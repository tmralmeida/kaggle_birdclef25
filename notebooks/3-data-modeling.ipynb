{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "183d000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os \n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    LearningRateMonitor,\n",
    "    EarlyStopping,\n",
    ")\n",
    "\n",
    "from birdclef.io import dump_json_file\n",
    "from birdclef.data_modeling.loader import BirdclefDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da2cf65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "KAGGLE_PATH = \"/Users/taa/Documents/kaggle/kaggle_birdclef25\"\n",
    "SPECTOGRAM_STYLE = \"mel\"  # \"mel\" or \"stft\"\n",
    "\n",
    "INPUT_DATA_MODEL = {\n",
    "    \"stft\" : (1025, 626),\n",
    "    \"mel\" : (128, 626)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26acbb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FILES/FOLDERS 3\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = os.path.join(KAGGLE_PATH, \"data\", \"processed\", SPECTOGRAM_STYLE)\n",
    "exisiting_files = os.listdir(DATA_PATH)\n",
    "print(\"Number of FILES/FOLDERS\", len(exisiting_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab87810",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = BirdclefDataset(\n",
    "    data_path=os.path.join(DATA_PATH, \"train\"),\n",
    "    set_type=\"train\",\n",
    ")\n",
    "val_ds = BirdclefDataset(\n",
    "    data_path=os.path.join(DATA_PATH, \"val\"),\n",
    "    set_type=\"val\",\n",
    "    label2id=train_ds.label2id,\n",
    "    id2label=train_ds.id2label,\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=14,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=14,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c03cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_sample, ex_label = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fff275d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1, 128, 626]), torch.Size([128]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_sample.shape, ex_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f9b7dc",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae6ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeb68d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecAugment(nn.Module):\n",
    "    def __init__(self, time_mask=30, freq_mask=13):\n",
    "        super().__init__()\n",
    "        self.time_mask = time_mask\n",
    "        self.freq_mask = freq_mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training:\n",
    "            return x  \n",
    "\n",
    "        for i in range(x.size(0)):\n",
    "            t = torch.randint(0, self.time_mask, (1,)).item()\n",
    "            f = torch.randint(0, self.freq_mask, (1,)).item()\n",
    "\n",
    "            t0 = torch.randint(0, max(1, x.size(3) - t), (1,)).item()\n",
    "            f0 = torch.randint(0, max(1, x.size(2) - f), (1,)).item()\n",
    "\n",
    "            x[i, 0, f0:f0+f, :] = 0  \n",
    "            x[i, 0, :, t0:t0+t] = 0 \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61a92e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEFCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout2d(0.3)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = self.pool(x).squeeze(-1).squeeze(-1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27a4079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BirdCLEFCNN(num_classes=len(train_ds.label2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65bc15b",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0041a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = self.ce(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        return (self.alpha * (1 - pt) ** self.gamma * ce_loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d482c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightModel(pl.LightningModule):\n",
    "    def __init__(self, model, n_classes: int, learning_rate=1e-3):\n",
    "        super(LightModel, self).__init__()\n",
    "        self.spec_augment = SpecAugment()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = FocalLoss()\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.spec_augment(x)\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=self.learning_rate,\n",
    "            weight_decay=1e-4,\n",
    "        )\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, patience=5, min_lr=1e-6)\n",
    "        return [opt], [dict(scheduler=lr_scheduler, interval=\"epoch\", monitor=\"train_loss\")]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y.long())\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch: dict, batch_idx: int) -> torch.Tensor:\n",
    "        x, y = val_batch\n",
    "        y_hat = self(x)\n",
    "        val_loss = self.criterion(y_hat, y.long())\n",
    "        self.log(\"val_loss\", val_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        final_preds = torch.nn.functional.softmax(y_hat, dim=-1)\n",
    "        self.update_metrics(final_preds, y.long())\n",
    "\n",
    "        return val_loss\n",
    "\n",
    "    def on_validation_start(self) -> None:\n",
    "        self.eval_metrics = dict(\n",
    "            accuracy=Accuracy(\n",
    "                task=\"multiclass\",\n",
    "                num_classes=self.n_classes,\n",
    "                average=\"weighted\",\n",
    "            ).to(self.device),\n",
    "            f1_score=F1Score(\n",
    "                task=\"multiclass\",\n",
    "                num_classes=self.n_classes,\n",
    "                average=\"weighted\",\n",
    "            ).to(self.device),\n",
    "            precision=Precision(\n",
    "                task=\"multiclass\",\n",
    "                num_classes=self.n_classes,\n",
    "                average=\"weighted\",\n",
    "            ).to(self.device),\n",
    "            recall=Recall(\n",
    "                task=\"multiclass\",\n",
    "                num_classes=self.n_classes,\n",
    "                average=\"weighted\",\n",
    "            ).to(self.device),\n",
    "        )\n",
    "\n",
    "    def on_validation_end(self) -> None:\n",
    "        save_path = os.path.join(self.logger.log_dir, \"val_metrics.json\")\n",
    "        val_metrics = self.compute_metrics()\n",
    "        dump_json_file(val_metrics, save_path)\n",
    "        self.reset_metrics()\n",
    "\n",
    "    def update_metrics(\n",
    "        self,\n",
    "        pred: torch.Tensor,\n",
    "        gt: torch.Tensor,\n",
    "    ):\n",
    "        self.eval_metrics[\"accuracy\"].update(preds=pred, target=gt)\n",
    "        self.eval_metrics[\"f1_score\"].update(preds=pred, target=gt)\n",
    "        self.eval_metrics[\"precision\"].update(preds=pred, target=gt)\n",
    "        self.eval_metrics[\"recall\"].update(preds=pred, target=gt)\n",
    "\n",
    "    def compute_metrics(self) -> dict:\n",
    "        final_metrics = {\n",
    "            met_name: met.compute().item() for met_name, met in self.eval_metrics.items()\n",
    "        }\n",
    "        return final_metrics\n",
    "\n",
    "    def reset_metrics(self) -> None:\n",
    "        for _, metric in self.eval_metrics.items():\n",
    "            metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c171903",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\n",
    "    f\"{KAGGLE_PATH}/lightning_logs/\", name=\"birdclef_specaugment\", default_hp_metric=False\n",
    ")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\", save_top_k=1, filename=\"{epoch}-{val_loss:.2f}\"\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.01,\n",
    "    patience=5,\n",
    "    verbose=False,\n",
    "    mode=\"min\",\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "callbacks = [early_stop_callback, checkpoint_callback, lr_monitor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab1c3ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type        | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | spec_augment | SpecAugment | 0      | train\n",
      "1 | model        | BirdCLEFCNN | 119 K  | train\n",
      "2 | criterion    | FocalLoss   | 0      | train\n",
      "-----------------------------------------------------\n",
      "119 K     Trainable params\n",
      "0         Non-trainable params\n",
      "119 K     Total params\n",
      "0.478     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  4.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taa/miniconda3/envs/kc_birds/lib/python3.11/site-packages/torch/nn/functional.py:1538: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  47%|████▋     | 318/674 [02:49<03:09,  1.87it/s, v_num=0, train_loss_step=3.660, train_loss_epoch=3.550, val_loss=3.470]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:339\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mself\u001b[39m.batch_progress.is_last_batch = data_fetcher.done\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mon_train_batch_end\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    340\u001b[39m call._call_lightning_module_hook(trainer, \u001b[33m\"\u001b[39m\u001b[33mon_train_batch_end\u001b[39m\u001b[33m\"\u001b[39m, batch_output, batch, batch_idx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:227\u001b[39m, in \u001b[36m_call_callback_hooks\u001b[39m\u001b[34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[39m\n\u001b[32m    226\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback.state_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m             \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[32m    230\u001b[39m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py:279\u001b[39m, in \u001b[36mTQDMProgressBar.on_train_batch_end\u001b[39m\u001b[34m(self, trainer, pl_module, outputs, batch, batch_idx)\u001b[39m\n\u001b[32m    278\u001b[39m _update_n(\u001b[38;5;28mself\u001b[39m.train_progress_bar, n)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28mself\u001b[39m.train_progress_bar.set_postfix(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/callbacks/progress/progress_bar.py:198\u001b[39m, in \u001b[36mProgressBar.get_metrics\u001b[39m\u001b[34m(self, trainer, pl_module)\u001b[39m\n\u001b[32m    197\u001b[39m standard_metrics = get_standard_metrics(trainer)\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m pbar_metrics = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprogress_bar_metrics\u001b[49m\n\u001b[32m    199\u001b[39m duplicates = \u001b[38;5;28mlist\u001b[39m(standard_metrics.keys() & pbar_metrics.keys())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1667\u001b[39m, in \u001b[36mTrainer.progress_bar_metrics\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1661\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"The metrics sent to the progress bar.\u001b[39;00m\n\u001b[32m   1662\u001b[39m \n\u001b[32m   1663\u001b[39m \u001b[33;03mThis includes metrics logged via :meth:`~pytorch_lightning.core.LightningModule.log` with the\u001b[39;00m\n\u001b[32m   1664\u001b[39m \u001b[33;03m:paramref:`~pytorch_lightning.core.LightningModule.log.prog_bar` argument set.\u001b[39;00m\n\u001b[32m   1665\u001b[39m \n\u001b[32m   1666\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1667\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_logger_connector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprogress_bar_metrics\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:254\u001b[39m, in \u001b[36m_LoggerConnector.progress_bar_metrics\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trainer._results:\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetrics\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mpbar\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._progress_bar_metrics.update(metrics)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:235\u001b[39m, in \u001b[36m_LoggerConnector.metrics\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trainer._results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_results\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mon_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:493\u001b[39m, in \u001b[36m_ResultCollection.metrics\u001b[39m\u001b[34m(self, on_step)\u001b[39m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result_metric.meta.prog_bar:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m         metrics[\u001b[33m\"\u001b[39m\u001b[33mpbar\u001b[39m\u001b[33m\"\u001b[39m][forked_name] = \u001b[43mconvert_tensors_to_scalars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/lightning_fabric/utilities/apply_func.py:136\u001b[39m, in \u001b[36mconvert_tensors_to_scalars\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value.item()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_to_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_item\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/lightning_utilities/core/apply_func.py:66\u001b[39m, in \u001b[36mapply_to_collection\u001b[39m\u001b[34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, dtype):  \u001b[38;5;66;03m# single element\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data.\u001b[34m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data):  \u001b[38;5;66;03m# 1d homogeneous list\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/lightning_fabric/utilities/apply_func.py:134\u001b[39m, in \u001b[36mconvert_tensors_to_scalars.<locals>.to_item\u001b[39m\u001b[34m(value)\u001b[39m\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    132\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe metric `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` does not contain a single element, thus it cannot be converted to a scalar.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m model = LightModel(model=model, n_classes=\u001b[38;5;28mlen\u001b[39m(train_ds.id2label), learning_rate=\u001b[32m1e-3\u001b[39m)\n\u001b[32m      2\u001b[39m trainer = pl.Trainer(\n\u001b[32m      3\u001b[39m     max_epochs=\u001b[32m100\u001b[39m,\n\u001b[32m      4\u001b[39m     accelerator=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     logger=logger,\n\u001b[32m     10\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# torch.save(model.state_dict(), \"birdclef_cnn.pth\")\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# # Load the model\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# model = LightModel(model=BirdCLEFCNN(num_classes=len(train_ds.labels)))\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# model.load_state_dict(torch.load(\"birdclef_cnn.pth\"))\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/kc_birds/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "model = LightModel(model=model, n_classes=len(train_ds.id2label), learning_rate=1e-3)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    enable_progress_bar=True,\n",
    "    check_val_every_n_epoch=2,\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    ")\n",
    "trainer.fit(model, train_dl, val_dl)\n",
    "# Save the model\n",
    "# torch.save(model.state_dict(), \"birdclef_cnn.pth\")\n",
    "# # Load the model\n",
    "# model = LightModel(model=BirdCLEFCNN(num_classes=len(train_ds.labels)))\n",
    "# model.load_state_dict(torch.load(\"birdclef_cnn.pth\"))\n",
    "# Set the model to evaluation mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kc_birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
